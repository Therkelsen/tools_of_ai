{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fc2d08d",
   "metadata": {},
   "source": [
    "Installation instructions:\n",
    "https://pytorch.org/get-started/locally/\n",
    "\n",
    "Also `pip install -r \"cifar100_transfer_learning_project\\src\\requirements.txt\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a81db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from thop import profile\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchinfo import summary\n",
    "from torchview import draw_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf1911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "checkpoint_dir = \"../models/checkpoints/\"\n",
    "top_models_dir = \"../models/top_models/\"\n",
    "dataset_dir = '../data/data_splits'\n",
    "shutil.rmtree(checkpoint_dir, ignore_errors=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(top_models_dir, exist_ok=True)\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "best_val_acc = 0\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7004dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing and class selection\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR100(root=\"../data/full_dataset\", train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR100(root=\"../data/full_dataset\", train=False, download=True, transform=transform_test)\n",
    "\n",
    "class_names = ['bicycle', 'bus', 'lawn_mower', 'motorcycle', 'pickup_truck', 'rocket', 'streetcar', 'tank', 'tractor', 'train']\n",
    "\n",
    "selected_classes = []\n",
    "for i in range(len(train_dataset.classes)):\n",
    "    if train_dataset.classes[i] in class_names:\n",
    "        selected_classes.append(i)\n",
    "\n",
    "print(\"Selected classes:\", class_names)\n",
    "\n",
    "# data subset for developing\n",
    "# num_train = 2000\n",
    "# num_test = 800\n",
    "# indices_train = random.sample(range(len(train_dataset)), num_train)\n",
    "# indices_test = random.sample(range(len(test_dataset)), num_test)\n",
    "# train_dataset = Subset(train_dataset, indices_train)\n",
    "# test_dataset = Subset(test_dataset, indices_test)\n",
    "\n",
    "class FilteredDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, selected_classes):\n",
    "        self.data = []\n",
    "        for img, label in dataset:\n",
    "            if label in selected_classes:\n",
    "                new_label = selected_classes.index(label)\n",
    "                self.data.append((img, new_label))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "train_filtered = FilteredDataset(train_dataset, selected_classes)\n",
    "test_filtered = FilteredDataset(test_dataset, selected_classes) \n",
    "\n",
    "train_stack = [] * len(train_filtered)\n",
    "train_tensor = [] * len(train_filtered)\n",
    "test_stack = [] * len(test_filtered)\n",
    "test_tensor = [] * len(test_filtered)\n",
    "\n",
    "for img, label in train_filtered:\n",
    "    train_stack.append(img)\n",
    "    train_tensor.append(label)\n",
    "for img, label in test_filtered:\n",
    "    test_stack.append(img)\n",
    "    test_tensor.append(label)\n",
    "    \n",
    "train_stack = torch.stack(train_stack)\n",
    "train_tensor = torch.tensor(train_tensor)\n",
    "test_stack = torch.stack(test_stack)\n",
    "test_tensor = torch.tensor(test_tensor)\n",
    "\n",
    "torch.save({\n",
    "    'images': train_stack,\n",
    "    'labels': train_tensor\n",
    "}, '../data/data_splits/train_filtered.pt')\n",
    "\n",
    "torch.save({\n",
    "    'images': test_stack,\n",
    "    'labels': test_tensor\n",
    "}, '../data/data_splits/test_filtered.pt')\n",
    "\n",
    "# Save selected classes\n",
    "with open(os.path.join(dataset_dir, 'selected_classes.pkl'), 'wb') as f:\n",
    "    pickle.dump(class_names, f)\n",
    "\n",
    "print(f\"Saved filtered datasets and class names in {dataset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1229d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "class_names = None\n",
    "with open(os.path.join(dataset_dir, 'selected_classes.pkl'), 'rb') as f:\n",
    "    class_names = pickle.load(f)\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "# Load full dataset\n",
    "data = torch.load(os.path.join(dataset_dir, 'train_filtered.pt'))\n",
    "full_dataset = SimpleDataset(data['images'], data['labels'])\n",
    "\n",
    "# Calculate split sizes\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0658999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model and prepare for training / testing/validation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load resnet18 pretrained model\n",
    "model_name = 'resnet18'\n",
    "num_classes = 10\n",
    "dropout_rate = 0.7\n",
    "dropout_path_rate = 0.2\n",
    "label_smoothing = 0.2\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 5e-4\n",
    "\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=num_classes, drop_rate=dropout_rate, drop_path_rate=dropout_path_rate)\n",
    "\n",
    "info = summary(model, input_size=(32, 3, 224, 224), col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"], row_settings=[\"var_names\"])\n",
    "print(info)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "# Label smoothing specifically works by adding a small value to the target labels and subtracting that value from the other labels.\n",
    "# This is done to prevent the model from becoming too confident in its predictions and to improve generalization.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "# AdamW optimizer is a variant of the Adam optimizer that decouples weight decay from the optimization steps.\n",
    "# Weight decay is a regularization technique that helps prevent overfitting by penalizing large weights.\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Custom score, this could be improved by adding confusion matrix based metrics\n",
    "# The score is calculated as a combination of the test accuracy, train accuracy, test loss, and train loss.\n",
    "def calculate_score(train_loss, val_loss, train_acc, val_acc):\n",
    "    return (val_acc + train_acc\n",
    "            - val_loss - train_loss\n",
    "            - abs(val_acc - train_acc)\n",
    "            - abs(val_loss - train_loss))\n",
    "\n",
    "# Training and testing functions\n",
    "def train(to_print = False):\n",
    "    model.train()\n",
    "    correct, total, running_loss = 0, 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    acc = 100. * correct / total\n",
    "    if to_print:\n",
    "        print(f\"\\tTrain Loss: {running_loss/len(train_loader):.3f}, Accuracy: {acc:.2f}%\")\n",
    "    return running_loss/len(train_loader), acc\n",
    "\n",
    "def validation(to_print = False):\n",
    "    model.eval()\n",
    "    correct, total, running_loss = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    acc = 100. * correct / total\n",
    "    if to_print:\n",
    "        print(f\"\\tValidation Loss: {running_loss/len(val_loader):.3f}, Accuracy: {acc:.2f}%\")\n",
    "    return running_loss/len(val_loader), acc\n",
    "\n",
    "# This is going to be run at the end of the entire training session, called with the best model.\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total, running_loss = 0, 0, 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    acc = 100. * correct / total\n",
    "    avg_loss = running_loss / len(test_loader)\n",
    "\n",
    "    print(f\"\\nTest Results — Loss: {avg_loss:.3f}, Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    return avg_loss, acc, all_preds, all_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4238348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10_000\n",
    "epochs_run = 0\n",
    "scheduler_learning_rate = 1e-4\n",
    "\n",
    "print_interval = max(1, num_epochs // 100)\n",
    "\n",
    "# Training loop\n",
    "train_losses = num_epochs * [0]\n",
    "val_losses = num_epochs * [0]\n",
    "train_accuracies = num_epochs * [0]\n",
    "val_accuracies = num_epochs * [0]\n",
    "\n",
    "# Initialize best metrics\n",
    "best_score = float('-inf')\n",
    "\n",
    "# Early stopping setup\n",
    "patience = max(1, num_epochs // 15)\n",
    "# patience = num_epochs\n",
    "epochs_since_improvement = 0\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=scheduler_learning_rate, steps_per_epoch=len(train_loader), epochs=num_epochs\n",
    ")\n",
    "\n",
    "to_print = False\n",
    "# for every epoch\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    start_time = time.time()\n",
    "    to_print = False\n",
    "    if epoch % print_interval == 0 or epoch == 1 or epoch == num_epochs:\n",
    "        to_print = True\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "    \n",
    "    # train the model and run testing / validation in realtime, instead of doing it at the end.\n",
    "    # This is to save time and resources, as we are not interested in the final model, but rather the best performing one.\n",
    "    train_loss, train_acc = train(to_print)\n",
    "    val_loss, val_acc = validation(to_print)\n",
    "    \n",
    "    train_losses[epoch - 1] = train_loss\n",
    "    val_losses[epoch - 1] = val_loss\n",
    "    train_accuracies[epoch - 1] = train_acc\n",
    "    val_accuracies[epoch - 1] = val_acc\n",
    "\n",
    "    save_checkpoint = False\n",
    "    \n",
    "    current_score = calculate_score(train_loss, val_loss, train_acc, val_acc)\n",
    "    if current_score > best_score:\n",
    "        best_score = current_score\n",
    "        save_checkpoint = True\n",
    "        epochs_since_improvement = 0\n",
    "    else:\n",
    "        epochs_since_improvement += 1\n",
    "\n",
    "    if save_checkpoint:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_acc': val_acc,\n",
    "        }, checkpoint_path)\n",
    "        if not to_print:\n",
    "            print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        print(f\"\\tTrain Loss: {train_loss/len(train_loader):.3f}, Accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"\\tTest Loss: {val_loss/len(test_loader):.3f}, Accuracy: {val_acc:.2f}%\")\n",
    "        print(f\"\\tCheckpoint saved at epoch {epoch}: {checkpoint_path}\")\n",
    "        if not to_print:\n",
    "            end_time = time.time()\n",
    "            print(f\"\\tTime taken: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    end_time = time.time()\n",
    "    if to_print:\n",
    "        print(f\"\\tTime taken: {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "    if epochs_since_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch} due to no improvement for {patience} epochs.\")\n",
    "        break\n",
    "\n",
    "    epochs_run += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saved models:\")\n",
    "\n",
    "def get_epoch_num(filename):\n",
    "    parts = filename.rstrip('.pth').split('_')\n",
    "    for part in reversed(parts):\n",
    "        if part.isdigit():\n",
    "            return int(part)\n",
    "    return -1\n",
    "\n",
    "def get_models_in_dir(directory):\n",
    "    model_files = []* len(os.listdir(directory))\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".pth\"):\n",
    "            model_files.append(filename)\n",
    "    return model_files\n",
    "\n",
    "model_files = get_models_in_dir(checkpoint_dir)\n",
    "\n",
    "# Gather and sort model files by epoch number\n",
    "print(f\"Found {len(model_files)} models in '{checkpoint_dir}'.\")\n",
    "\n",
    "def sort_models_by_score(model_files, models_path):\n",
    "    # Load models, calculate scores, and store metadata\n",
    "    model_scores = [] * len(model_files)\n",
    "    for filename in model_files:\n",
    "        path = os.path.join(models_path, filename)\n",
    "        checkpoint = torch.load(path)\n",
    "\n",
    "        train_loss = checkpoint.get('train_loss', 0)\n",
    "        val_loss = checkpoint.get('val_loss', 0)\n",
    "        train_acc = checkpoint.get('train_acc', 0)\n",
    "        val_acc = checkpoint.get('val_acc', 0)\n",
    "        epoch_num = checkpoint.get('epoch', get_epoch_num(filename))\n",
    "\n",
    "        score = calculate_score(train_loss, val_loss, train_acc, val_acc)\n",
    "\n",
    "        model_scores.append((filename, score, train_loss, train_acc, val_loss, val_acc, epoch_num))\n",
    "\n",
    "    model_scores_sorted = sorted(model_scores, key=lambda x: x[1], reverse=True)\n",
    "    print(f\"\\nModels sorted by score:\")\n",
    "    for i, (filename, score, train_loss, train_acc, val_loss, val_acc, epoch_num) in enumerate(model_scores_sorted):\n",
    "        print(f\"{i + 1}: {filename} | Epoch {epoch_num} | \"\n",
    "            f\"TrL: {train_loss:.3f}, TrA: {train_acc:.2f}%, \"\n",
    "            f\"TeL: {val_loss:.3f}, TeA: {val_acc:.2f}%, \"\n",
    "            f\"Score: {score:.3f}\")\n",
    "    # Sort all models by score descending\n",
    "    return model_scores_sorted\n",
    "\n",
    "model_scores_sorted = sort_models_by_score(model_files, checkpoint_dir)\n",
    "\n",
    "print(f\"\\nBest model will be moved to '{top_models_dir}'.\")\n",
    "\n",
    "filename, score, train_loss, train_acc, val_loss, val_acc, epoch_num = model_scores_sorted[0]\n",
    "src = os.path.join(checkpoint_dir, filename)\n",
    "new_filename = (f\"model-\\'{model_name}\\'_\"\n",
    "                f\"eps-{epoch_num}_\"\n",
    "                f\"TrL-{train_loss:.3f}_\"\n",
    "                f\"TrA-{train_acc:.2f}%_\"\n",
    "                f\"TeL-{val_loss:.3f}_\"\n",
    "                f\"TeA-{val_acc:.2f}%_\"\n",
    "                f\"sc-{score:.3f}_.pth\")\n",
    "dest = os.path.join(top_models_dir, new_filename)\n",
    "shutil.move(src, dest)\n",
    "\n",
    "print(f\"Moved the top model to '{top_models_dir}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best model will be loaded from '{top_models_dir}'.\")\n",
    "top_model_files = get_models_in_dir(top_models_dir)\n",
    "print(f\"Found {len(top_model_files)} models in '{top_models_dir}'.\")\n",
    "model_scores_sorted = sort_models_by_score(top_model_files, top_models_dir)\n",
    "best_model = model_scores_sorted[0]\n",
    "\n",
    "print(f\"Best model: {best_model}\")\n",
    "# find path to model\n",
    "best_model_path = os.path.join(top_models_dir, best_model[0])\n",
    "best_model = torch.load(best_model_path)\n",
    "model.load_state_dict(best_model['model_state_dict'])\n",
    "model = model.to(device)\n",
    "\n",
    "test(model=model, test_loader=test_loader)\n",
    "\n",
    "def plot_performance_metrics(mark_best=None):\n",
    "# Plot performance metrics and mark best model\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    best_model_val_loss = None\n",
    "    best_model_val_acc = None\n",
    "    if mark_best is not None:\n",
    "        # Find best model by highest test accuracy\n",
    "        best_model_index = mark_best.index(max(mark_best, key=lambda x: x[1]))\n",
    "        best_model_epoch = mark_best[best_model_index][6]\n",
    "        best_model_val_loss = mark_best[best_model_index][4]\n",
    "        best_model_val_acc = mark_best[best_model_index][5]\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses[:epochs_run], label='Train Loss')\n",
    "    plt.plot(val_losses[:epochs_run], label='Test Loss')\n",
    "    plt.scatter(best_model_epoch, best_model_val_loss, color='red', label='Best Model', zorder=5) if best_model_val_loss is not None else None\n",
    "    plt.title('Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies[:epochs_run], label='Train Accuracy')\n",
    "    plt.plot(val_accuracies[:epochs_run], label='Test Accuracy')\n",
    "    plt.scatter(best_model_epoch, best_model_val_acc, color='red', label='Best Model', zorder=5) if best_model_val_acc is not None else None\n",
    "    plt.title('Accuracy per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    print(f\"Training Loss: {train_losses[:epochs_run]}\")\n",
    "    print(f\"Test Loss: {val_losses[:epochs_run]}\")\n",
    "    print(f\"Training Accuracy: {train_accuracies[:epochs_run]}%\")\n",
    "    print(f\"Test Accuracy: {val_accuracies[:epochs_run]}%\")\n",
    "\n",
    "def generate_confusion_matrix(model, test_loader, class_names, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "def print_confusion_matrix(cm, class_names):\n",
    "    print(\"Confusion Matrix (rows = true labels, columns = predicted labels):\")\n",
    "    print(\"\\t\" + \"\\t\".join(class_names))\n",
    "    for i, row in enumerate(cm):\n",
    "        print(f\"{class_names[i]}\\t\" + \"\\t\".join(map(str, row)))\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def calculate_metrics(cm):\n",
    "    epsilon = 1e-10\n",
    "    tp = np.diag(cm)\n",
    "    fn = np.sum(cm, axis=1) - tp\n",
    "    fp = np.sum(cm, axis=0) - tp\n",
    "    tn = np.sum(cm) - (tp + fp + fn)\n",
    "    \n",
    "    print(f\"TP: {tp}\")\n",
    "    print(f\"FP: {fp}\")\n",
    "    print(f\"TN: {tn}\")\n",
    "    print(f\"FN: {fn}\")\n",
    "\n",
    "    accuracy = np.sum(tp) / np.sum(cm)\n",
    "\n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "    specificity = tn / (tn + fp + epsilon)\n",
    "    f1 = 2 * precision * recall / (precision + recall + epsilon)\n",
    "\n",
    "    return accuracy, precision, recall, specificity, f1\n",
    "\n",
    "plot_performance_metrics(mark_best=model_scores_sorted)\n",
    "\n",
    "cm = generate_confusion_matrix(model, test_loader, class_names, device)\n",
    "print_confusion_matrix(cm, class_names)\n",
    "\n",
    "accuracy, precision, recall, specificity, f1_score = calculate_metrics(cm)\n",
    "\n",
    "print(\"\\nMetrics Based on Confusion Matrix:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"\\nClass: {name}\")\n",
    "    print(f\"  Precision:  {precision[i]:.4f}\")\n",
    "    print(f\"  Recall:     {recall[i]:.4f}\")\n",
    "    print(f\"  Specificity:{specificity[i]:.4f}\")\n",
    "    print(f\"  F1-score:   {f1_score[i]:.4f}\")\n",
    "    \n",
    "macs, params = profile(model, inputs=(torch.randn(1, 3, 224, 224).to(device),))\n",
    "print(f\"FLOPs: {macs / 1e6:.2f} MFLOPs, Params: {params/1e6:.2f} M\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "graph = draw_graph(\n",
    "    model,\n",
    "    input_size=(1, 3, 224, 224),  # batch size of 1\n",
    "    expand_nested=False,\n",
    "    roll=False,\n",
    "    device=\"cpu\",\n",
    "    depth=3,\n",
    ")\n",
    "\n",
    "graph.visual_graph\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
